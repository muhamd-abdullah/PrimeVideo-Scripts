{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d41e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import result data\n",
    "import os\n",
    "import csv\n",
    "\n",
    "RESULT_PATH = \"./results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0314835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/ False\n",
      "./results/peak-28-06-2023_15hh_45mm_TO_28-06-2023_16hh_35mm False\n",
      "adding 0_combined_pickle.pkl\tfrom: ./results/peak-28-06-2023_15hh_45mm_TO_28-06-2023_16hh_35mm\n",
      "adding 0_combined_pickle.pkl in peak\n",
      "\n",
      "./results/peak-28-06-2023_20hh_40mm_TO_28-06-2023_21hh_14mm False\n",
      "adding 0_combined_pickle.pkl\tfrom: ./results/peak-28-06-2023_20hh_40mm_TO_28-06-2023_21hh_14mm\n",
      "adding 0_combined_pickle.pkl in peak\n",
      "\n",
      "./results/peak-28-06-2023_10hh_32mm_TO_28-06-2023_15hh_42mm False\n",
      "adding 0_combined_pickle.pkl\tfrom: ./results/peak-28-06-2023_10hh_32mm_TO_28-06-2023_15hh_42mm\n",
      "adding 0_combined_pickle.pkl in peak\n",
      "\n",
      "./results/nonpeak-28-06-2023_06hh_17mm_TO_28-06-2023_10hh_31mm False\n",
      "adding 0_combined_pickle.pkl\tfrom: ./results/nonpeak-28-06-2023_06hh_17mm_TO_28-06-2023_10hh_31mm\n",
      "adding 0_combined_pickle.pkl in nonpeak\n",
      "\n",
      "./results/peak-28-06-2023_21hh_23mm_TO_28-06-2023_22hh_39mm False\n",
      "adding 0_combined_pickle.pkl\tfrom: ./results/peak-28-06-2023_21hh_23mm_TO_28-06-2023_22hh_39mm\n",
      "adding 0_combined_pickle.pkl in peak\n",
      "\n",
      "./results/nonpeak-27-06-2023_06hh_22mm_TO_28-06-2023_00hh_51mm False\n",
      "adding 0_combined_pickle.pkl\tfrom: ./results/nonpeak-27-06-2023_06hh_22mm_TO_28-06-2023_00hh_51mm\n",
      "adding 0_combined_pickle.pkl in nonpeak\n",
      "\n",
      "102893 325842\n"
     ]
    }
   ],
   "source": [
    "### READ ALL PICKLES INTO DATAFRAME\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "combined_peak_df = pd.DataFrame()\n",
    "combined_nonpeak_df = pd.DataFrame()\n",
    "\n",
    "for root, dirs, files in os.walk(RESULT_PATH):\n",
    "    print(root, \"old\" in root)\n",
    "    for i, file in enumerate(files):\n",
    "        if file.endswith('.pkl') and \"old\" not in root:\n",
    "            print(f\"adding {file}\\tfrom: {root}\")\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                df = pickle.load(f)\n",
    "                if \"nonpeak\" in file_path:\n",
    "                    print(f\"adding {file} in nonpeak\\n\")\n",
    "                    combined_nonpeak_df = pd.concat([combined_nonpeak_df,df], ignore_index=True)\n",
    "                else:\n",
    "                    print(f\"adding {file} in peak\\n\")\n",
    "                    combined_peak_df = pd.concat([combined_peak_df, df], ignore_index=True)\n",
    "\n",
    "peak_count = len(combined_peak_df)\n",
    "nonpeak_count= len(combined_nonpeak_df)\n",
    "print(peak_count, nonpeak_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([combined_nonpeak_df, combined_nonpeak_df])\n",
    "\n",
    "pop_to_all_ips = {}\n",
    "pop_to_ip = {}\n",
    "\n",
    "cf_pop = df['X-Amz-Cf-Pop'].tolist()\n",
    "cf_ip = df['responseIP'].tolist()\n",
    "for pop, ip in zip(cf_pop, cf_ip):\n",
    "    if pop in pop_to_all_ips:\n",
    "        ips = pop_to_all_ips[pop]\n",
    "        ips.append(ip)\n",
    "        pop_to_all_ips[pop] = ips\n",
    "    else:\n",
    "        pop_to_all_ips[pop] = [ip]\n",
    "\n",
    "\n",
    "for pop, ips in pop_to_all_ips.items():\n",
    "    if pop not in pop_to_ip:\n",
    "        ip = statistics.mode(ips)\n",
    "        pop_to_ip[pop] = ip\n",
    "        print (f\"'{pop}' : '{ip}',\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a6f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LATENCY CDF DURING PEAK TIME\n",
    "import numpy as np\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# filter content into dfs\n",
    "df = combined_peak_df\n",
    "top_content_list = []\n",
    "with open(\"top_content_movies.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_movies.csv\"\n",
    "        top_content_list.append(line)\n",
    "with open(\"top_content_tv.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_tv.csv\"\n",
    "        top_content_list.append(line)\n",
    "\n",
    "top10_df = df[df['content'].isin(top_content_list)]\n",
    "popular_df = df[df['content'].str.contains('_top_')]\n",
    "popular_df = popular_df[~popular_df['content'].isin(top_content_list)]\n",
    "nonpopular_df = df[~df['content'].str.contains('_top_|myvideo|_recentlyadded_')]\n",
    "mycontent_df = df[df['content'].str.contains('myvideo')]\n",
    "recentlyadded_df = df[df['content'].str.contains('_recentlyadded_')]\n",
    "\n",
    "\n",
    "# Calculate the CDF values\n",
    "top10_df['latency(ms)'] = pd.to_numeric(top10_df['latency(ms)'], errors='coerce')\n",
    "ecdf_top10 = sm.distributions.ECDF(top10_df['latency(ms)'])\n",
    "x_top10 = sorted(top10_df['latency(ms)'].unique())\n",
    "y_top10 = ecdf_top10(x_top10)\n",
    "\n",
    "popular_df['latency(ms)'] = pd.to_numeric(popular_df['latency(ms)'], errors='coerce')\n",
    "ecdf_popular = sm.distributions.ECDF(popular_df['latency(ms)'])\n",
    "x_popular = sorted(popular_df['latency(ms)'].unique())\n",
    "y_popular = ecdf_popular(x_popular)\n",
    "\n",
    "nonpopular_df['latency(ms)'] = pd.to_numeric(nonpopular_df['latency(ms)'], errors='coerce')\n",
    "ecdf_nonpopular = sm.distributions.ECDF(nonpopular_df['latency(ms)'])\n",
    "x_nonpopular = sorted(nonpopular_df['latency(ms)'].unique())\n",
    "y_nonpopular = ecdf_nonpopular(x_nonpopular)\n",
    "\n",
    "mycontent_df['latency(ms)'] = pd.to_numeric(mycontent_df['latency(ms)'], errors='coerce')\n",
    "ecdf_mycontent = sm.distributions.ECDF(mycontent_df['latency(ms)'])\n",
    "x_mycontent = sorted(mycontent_df['latency(ms)'].unique())\n",
    "y_mycontent = ecdf_mycontent(x_mycontent)\n",
    "\n",
    "recentlyadded_df['latency(ms)'] = pd.to_numeric(recentlyadded_df['latency(ms)'], errors='coerce')\n",
    "ecdf_recentlyadded = sm.distributions.ECDF(recentlyadded_df['latency(ms)'])\n",
    "x_recentlyadded = sorted(recentlyadded_df['latency(ms)'].unique())\n",
    "y_recentlyadded = ecdf_recentlyadded(x_recentlyadded)\n",
    "\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Calculate the averages\n",
    "average_top10 = top10_df['latency(ms)'].mean()\n",
    "average_popular = popular_df['latency(ms)'].mean()\n",
    "average_nonpopular = nonpopular_df['latency(ms)'].mean()\n",
    "average_mycontent = mycontent_df['latency(ms)'].mean()\n",
    "average_recentlyadded = recentlyadded_df['latency(ms)'].mean()\n",
    "print(f\"AVERAGE LATENCY (PEAK):\\ntop10: {average_top10}\\npopular: {average_popular}\\nnonpopular: {average_nonpopular}\\nmycontent: {average_mycontent}\\nrecentlyadded: {average_recentlyadded}\")\n",
    "\n",
    "# Plot the median lines\n",
    "plt.axhline(0.5, linestyle='--', color='grey')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Latency (ms)')\n",
    "plt.ylabel('CDF')\n",
    "plt.title('CDF of latencies during peak time')\n",
    "\n",
    "plt.plot(x_top10, y_top10, linestyle='-', label='top-10 content')  # Solid line\n",
    "plt.plot(x_popular, y_popular, linestyle='--', label='popular content')  # Dashed line\n",
    "plt.plot(x_nonpopular, y_nonpopular, linestyle='-', label='unpopular content')  # Dotted line\n",
    "plt.plot(x_mycontent, y_mycontent, linestyle='-.', label='our content')  # Dash-dot line\n",
    "plt.plot(x_recentlyadded, y_recentlyadded, linestyle=':', label='recently added content')  # Solid line\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b39865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LATENCY CDF DURING NON-PEAK TIME\n",
    "import numpy as np\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# filter content into dfs\n",
    "df = combined_nonpeak_df\n",
    "top_content_list = []\n",
    "with open(\"top_content_movies.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_movies.csv\"\n",
    "        top_content_list.append(line)\n",
    "with open(\"top_content_tv.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_tv.csv\"\n",
    "        top_content_list.append(line)\n",
    "\n",
    "top10_df = df[df['content'].isin(top_content_list)]\n",
    "popular_df = df[df['content'].str.contains('_top_')]\n",
    "popular_df = popular_df[~popular_df['content'].isin(top_content_list)]\n",
    "nonpopular_df = df[~df['content'].str.contains('_top_|myvideo|_recentlyadded_')]\n",
    "mycontent_df = df[df['content'].str.contains('myvideo')]\n",
    "recentlyadded_df = df[df['content'].str.contains('_recentlyadded_')]\n",
    "\n",
    "\n",
    "# Calculate the CDF values\n",
    "top10_df['latency(ms)'] = pd.to_numeric(top10_df['latency(ms)'], errors='coerce')\n",
    "ecdf_top10 = sm.distributions.ECDF(top10_df['latency(ms)'])\n",
    "x_top10 = sorted(top10_df['latency(ms)'].unique())\n",
    "y_top10 = ecdf_top10(x_top10)\n",
    "\n",
    "popular_df['latency(ms)'] = pd.to_numeric(popular_df['latency(ms)'], errors='coerce')\n",
    "ecdf_popular = sm.distributions.ECDF(popular_df['latency(ms)'])\n",
    "x_popular = sorted(popular_df['latency(ms)'].unique())\n",
    "y_popular = ecdf_popular(x_popular)\n",
    "\n",
    "nonpopular_df['latency(ms)'] = pd.to_numeric(nonpopular_df['latency(ms)'], errors='coerce')\n",
    "ecdf_nonpopular = sm.distributions.ECDF(nonpopular_df['latency(ms)'])\n",
    "x_nonpopular = sorted(nonpopular_df['latency(ms)'].unique())\n",
    "y_nonpopular = ecdf_nonpopular(x_nonpopular)\n",
    "\n",
    "mycontent_df['latency(ms)'] = pd.to_numeric(mycontent_df['latency(ms)'], errors='coerce')\n",
    "ecdf_mycontent = sm.distributions.ECDF(mycontent_df['latency(ms)'])\n",
    "x_mycontent = sorted(mycontent_df['latency(ms)'].unique())\n",
    "y_mycontent = ecdf_mycontent(x_mycontent)\n",
    "\n",
    "recentlyadded_df['latency(ms)'] = pd.to_numeric(recentlyadded_df['latency(ms)'], errors='coerce')\n",
    "ecdf_recentlyadded = sm.distributions.ECDF(recentlyadded_df['latency(ms)'])\n",
    "x_recentlyadded = sorted(recentlyadded_df['latency(ms)'].unique())\n",
    "y_recentlyadded = ecdf_recentlyadded(x_recentlyadded)\n",
    "\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Calculate the averages\n",
    "average_top10 = top10_df['latency(ms)'].mean()\n",
    "average_popular = popular_df['latency(ms)'].mean()\n",
    "average_nonpopular = nonpopular_df['latency(ms)'].mean()\n",
    "average_mycontent = mycontent_df['latency(ms)'].mean()\n",
    "average_recentlyadded = recentlyadded_df['latency(ms)'].mean()\n",
    "print(f\"AVERAGE LATENCY (NON-PEAK):\\ntop10: {average_top10}\\npopular: {average_popular}\\nnonpopular: {average_nonpopular}\\nmycontent: {average_mycontent}\\nrecentlyadded: {average_recentlyadded}\")\n",
    "\n",
    "# Plot the median lines\n",
    "plt.axhline(0.5, linestyle='--', color='grey')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Latency (ms)')\n",
    "plt.ylabel('CDF')\n",
    "plt.title('CDF of latencies during non-peak time')\n",
    "\n",
    "plt.plot(x_top10, y_top10, linestyle='-', label='top-10 content')  # Solid line\n",
    "plt.plot(x_popular, y_popular, linestyle='--', label='popular content')  # Dashed line\n",
    "plt.plot(x_nonpopular, y_nonpopular, linestyle='-', label='unpopular content')  # Dotted line\n",
    "plt.plot(x_mycontent, y_mycontent, linestyle='-.', label='our content')  # Dash-dot line\n",
    "plt.plot(x_recentlyadded, y_recentlyadded, linestyle=':', label='recently added content')  # Solid line\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952275c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BOXPLOT OF LATENCIES DURING PEAK-TIME\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# filter content into dfs\n",
    "df = combined_peak_df\n",
    "top_content_list = []\n",
    "with open(\"top_content_movies.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_movies.csv\"\n",
    "        top_content_list.append(line)\n",
    "with open(\"top_content_tv.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_tv.csv\"\n",
    "        top_content_list.append(line)\n",
    "\n",
    "top10_df = df[df['content'].isin(top_content_list)]\n",
    "popular_df = df[df['content'].str.contains('_top_')]\n",
    "popular_df = popular_df[~popular_df['content'].isin(top_content_list)]\n",
    "nonpopular_df = df[~df['content'].str.contains('_top_|myvideo|_recentlyadded_')]\n",
    "mycontent_df = df[df['content'].str.contains('myvideo')]\n",
    "recentlyadded_df = df[df['content'].str.contains('_recentlyadded_')]\n",
    "\n",
    "# Create a list of latency values for each DataFrame\n",
    "latency_data = [\n",
    "    mycontent_df['latency(ms)'],\n",
    "    top10_df['latency(ms)'],\n",
    "    popular_df['latency(ms)'],\n",
    "    nonpopular_df['latency(ms)'],\n",
    "    recentlyadded_df['latency(ms)']\n",
    "]\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create the box plots\n",
    "plt.boxplot(latency_data, showfliers=True, whis=100, meanline=True, showmeans=True, meanprops={'marker':'^', 'markerfacecolor':'red', 'markeredgecolor':'red'})\n",
    "\n",
    "# Set x-axis tick labels\n",
    "labels = ['our content', 'top-10 content', 'popular content', 'unpopular content', 'recently added content']\n",
    "plt.xticks(range(1, len(labels) + 1), labels)\n",
    "\n",
    "# Set labels and title\n",
    "#plt.xlabel('Dataframes')\n",
    "plt.ylabel('Latency (ms)')\n",
    "plt.title('Box Plots of latency during peak time')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BOXPLOT OF LATENCIES DURING NON-PEAK-TIME\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# filter content into dfs\n",
    "df = combined_nonpeak_df\n",
    "top_content_list = []\n",
    "with open(\"top_content_movies.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_movies.csv\"\n",
    "        top_content_list.append(line)\n",
    "with open(\"top_content_tv.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_tv.csv\"\n",
    "        top_content_list.append(line)\n",
    "\n",
    "top10_df = df[df['content'].isin(top_content_list)]\n",
    "popular_df = df[df['content'].str.contains('_top_')]\n",
    "popular_df = popular_df[~popular_df['content'].isin(top_content_list)]\n",
    "nonpopular_df = df[~df['content'].str.contains('_top_|myvideo|_recentlyadded_')]\n",
    "mycontent_df = df[df['content'].str.contains('myvideo')]\n",
    "recentlyadded_df = df[df['content'].str.contains('_recentlyadded_')]\n",
    "\n",
    "top10_df['latency(ms)'] = pd.to_numeric(top10_df['latency(ms)'], errors='coerce')\n",
    "top10_df.dropna(subset=['latency(ms)'], inplace=True)\n",
    "\n",
    "popular_df['latency(ms)'] = pd.to_numeric(popular_df['latency(ms)'], errors='coerce')\n",
    "popular_df.dropna(subset=['latency(ms)'], inplace=True)\n",
    "\n",
    "nonpopular_df['latency(ms)'] = pd.to_numeric(nonpopular_df['latency(ms)'], errors='coerce')\n",
    "nonpopular_df.dropna(subset=['latency(ms)'], inplace=True)\n",
    "\n",
    "mycontent_df['latency(ms)'] = pd.to_numeric(mycontent_df['latency(ms)'], errors='coerce')\n",
    "mycontent_df.dropna(subset=['latency(ms)'], inplace=True)\n",
    "\n",
    "recentlyadded_df['latency(ms)'] = pd.to_numeric(recentlyadded_df['latency(ms)'], errors='coerce')\n",
    "recentlyadded_df.dropna(subset=['latency(ms)'], inplace=True)\n",
    "\n",
    "# Create a list of latency values for each DataFrame\n",
    "latency_data = [\n",
    "    mycontent_df['latency(ms)'],\n",
    "    top10_df['latency(ms)'],\n",
    "    popular_df['latency(ms)'],\n",
    "    nonpopular_df['latency(ms)'],\n",
    "    recentlyadded_df['latency(ms)']\n",
    "]\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create the box plots\n",
    "plt.boxplot(latency_data, showfliers=True, whis=100, meanline=True, showmeans=True, meanprops={'marker':'^', 'markerfacecolor':'red', 'markeredgecolor':'red'})\n",
    "\n",
    "# Set x-axis tick labels\n",
    "labels = ['our content', 'top-10 content', 'popular content', 'unpopular content', 'recently added content']\n",
    "plt.xticks(range(1, len(labels) + 1), labels)\n",
    "\n",
    "# Set labels and title\n",
    "#plt.xlabel('Dataframes')\n",
    "plt.ylabel('Latency (ms)')\n",
    "plt.title('Box Plots of latency during non-peak time')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5806c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# filter content into dfs\n",
    "df = pd.concat([combined_peak_df, combined_nonpeak_df])\n",
    "\n",
    "pops = df['X-Amz-Cf-Pop'].unique()\n",
    "pops = set([pop[:3] for pop in pops])\n",
    "\n",
    "edge_cities = []\n",
    "latencies = []\n",
    "\n",
    "print(\"*** AVG EDGE LATENCIES ***\")\n",
    "for pop in pops:\n",
    "    pop = pop[:3]\n",
    "    current_df = df[df['X-Amz-Cf-Pop'].str.contains(pop)]\n",
    "    current_df['latency(ms)'] = pd.to_numeric(current_df['latency(ms)'], errors='coerce')\n",
    "    mean_latency = round(current_df['latency(ms)'].mean(), 2)\n",
    "    if pop != \" \":\n",
    "        print(pop, round(mean_latency, 2))\n",
    "        edge_cities.append(pop)\n",
    "        latencies.append(mean_latency)\n",
    "\n",
    "# Overall average of all latencies\n",
    "df['latency(ms)'] = pd.to_numeric(df['latency(ms)'], errors='coerce')\n",
    "overall_average = round(df['latency(ms)'].mean(), 2)\n",
    "\n",
    "# Generate random colors for the bars\n",
    "colors = np.random.rand(len(edge_cities), 3)\n",
    "\n",
    "# Plot the horizontal bar chart\n",
    "plt.barh(edge_cities, latencies, color=colors)\n",
    "plt.axvline(x=overall_average, color='r', linestyle='--', label='Overall Average')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Avg. Latency (ms)')\n",
    "plt.ylabel('PoP Location')\n",
    "plt.title('Average Latency to PoPs')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c868637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROUTING TO EDGE/POP DISTRIBUTION DURING PEAK TIME\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# filter content into dfs\n",
    "df = combined_peak_df\n",
    "top_content_list = []\n",
    "with open(\"top_content_movies.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_movies.csv\"\n",
    "        top_content_list.append(line)\n",
    "with open(\"top_content_tv.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_tv.csv\"\n",
    "        top_content_list.append(line)\n",
    "\n",
    "top10_df = df[df['content'].isin(top_content_list)]\n",
    "popular_df = df[df['content'].str.contains('_top_')]\n",
    "popular_df = popular_df[~popular_df['content'].isin(top_content_list)]\n",
    "nonpopular_df = df[~df['content'].str.contains('_top_|myvideo|_recentlyadded_')]\n",
    "mycontent_df = df[df['content'].str.contains('myvideo')]\n",
    "recentlyadded_df = df[df['content'].str.contains('_recentlyadded_')]\n",
    "\n",
    "\n",
    "\n",
    "dfs = [top10_df, popular_df, nonpopular_df, mycontent_df, recentlyadded_df]\n",
    "titles = [\"Top-10\", \"Popular\", \"Non-popular\", \"My content\", \"Recently added\"]\n",
    "# Create a figure with 1 row and 5 columns of subplots\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 5))\n",
    "\n",
    "# Iterate over the DataFrames and plot the pie charts\n",
    "for i, df in enumerate(dfs):\n",
    "    df['X-Amz-Cf-Pop'] = df['X-Amz-Cf-Pop'].str[:3]\n",
    "    df['X-Amz-Cf-Pop'] = df['X-Amz-Cf-Pop'].str.replace(\" \", \"N/A\")\n",
    "    city_counts = df['X-Amz-Cf-Pop'].value_counts()\n",
    "    city_percentages = city_counts / len(df) * 100\n",
    "    city_percentages = city_percentages[city_percentages >= 0.1]\n",
    "    axs[i].pie(city_percentages, labels=city_percentages.index, autopct='%1.1f%%', textprops={'fontsize': 10})\n",
    "    axs[i].set_title(f'{titles[i]}')\n",
    "    axs[i].axis('equal')\n",
    "\n",
    "# Add a title on top\n",
    "fig.suptitle('Content routing distribution during peak time', fontsize=16)\n",
    "\n",
    "# Adjust the spacing between subplots and legend\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "### PIE-CHART WITH FURTHER BREAKDOWN\n",
    "df = combined_nonpeak_df\n",
    "top10_df = df[df['content'].isin(top_content_list)]\n",
    "popular_df = df[df['content'].str.contains('_top_')]\n",
    "popular_df = popular_df[~popular_df['content'].isin(top_content_list)]\n",
    "nonpopular_df = df[~df['content'].str.contains('_top_|myvideo|_recentlyadded_')]\n",
    "mycontent_df = df[df['content'].str.contains('myvideo')]\n",
    "recentlyadded_df = df[df['content'].str.contains('_recentlyadded_')]\n",
    "\n",
    "# Create list of dfs for pie charts\n",
    "dfs = [top10_df, popular_df, nonpopular_df, mycontent_df, recentlyadded_df]\n",
    "titles = [\"Top-10\", \"Popular\", \"Non-popular\", \"My content\", \"Recently added\"]\n",
    "\n",
    "\n",
    "# Create a figure with 1 row and 5 columns of subplots\n",
    "fig, axs = plt.subplots(1, 5, figsize=(25, 5))\n",
    "\n",
    "# Iterate over the DataFrames and plot the pie charts\n",
    "for i, df in enumerate(dfs):\n",
    "    #df['X-Amz-Cf-Pop'] = df['X-Amz-Cf-Pop'].str[:3]\n",
    "    df['X-Amz-Cf-Pop'] = df['X-Amz-Cf-Pop'].str.replace(\" \", \"N/A\")\n",
    "    city_counts = df['X-Amz-Cf-Pop'].value_counts()\n",
    "    city_percentages = city_counts / len(df) * 100\n",
    "    city_percentages = city_percentages[city_percentages >= 0.1]\n",
    "    axs[i].pie(city_percentages, labels=city_percentages.index, autopct='%1.1f%%', textprops={'fontsize': 8})\n",
    "    axs[i].set_title(f'{titles[i]}')\n",
    "    axs[i].axis('equal')\n",
    "\n",
    "# Add a title on top\n",
    "fig.suptitle('Content routing distribution during peak hours (breakdown by PoPs)', fontsize=16)\n",
    "\n",
    "# Adjust the spacing between subplots and legend\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROUTING TO EDGE/POP DISTRIBUTION DURING NON-PEAK TIME\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# filter content into dfs\n",
    "df = combined_nonpeak_df\n",
    "top_content_list = []\n",
    "with open(\"top_content_movies.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_movies.csv\"\n",
    "        top_content_list.append(line)\n",
    "with open(\"top_content_tv.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_tv.csv\"\n",
    "        top_content_list.append(line)\n",
    "top10_df = df[df['content'].isin(top_content_list)]\n",
    "popular_df = df[df['content'].str.contains('_top_')]\n",
    "popular_df = popular_df[~popular_df['content'].isin(top_content_list)]\n",
    "nonpopular_df = df[~df['content'].str.contains('_top_|myvideo|_recentlyadded_')]\n",
    "mycontent_df = df[df['content'].str.contains('myvideo')]\n",
    "recentlyadded_df = df[df['content'].str.contains('_recentlyadded_')]\n",
    "\n",
    "# Create list of dfs for pie charts\n",
    "dfs = [top10_df, popular_df, nonpopular_df, mycontent_df, recentlyadded_df]\n",
    "titles = [\"Top-10\", \"Popular\", \"Non-popular\", \"My content\", \"Recently added\"]\n",
    "\n",
    "\n",
    "# Create a figure with 1 row and 5 columns of subplots\n",
    "fig, axs = plt.subplots(1, 5, figsize=(25, 6))\n",
    "\n",
    "# Iterate over the DataFrames and plot the pie charts\n",
    "for i, df in enumerate(dfs):\n",
    "    df['X-Amz-Cf-Pop'] = df['X-Amz-Cf-Pop'].str[:3]\n",
    "    df['X-Amz-Cf-Pop'] = df['X-Amz-Cf-Pop'].str.replace(\" \", \"N/A\")\n",
    "    city_counts = df['X-Amz-Cf-Pop'].value_counts()\n",
    "    city_percentages = city_counts / len(df) * 100\n",
    "    city_percentages = city_percentages[city_percentages >= 0.1]\n",
    "    axs[i].pie(city_percentages, labels=city_percentages.index, autopct='%1.1f%%', textprops={'fontsize': 10})\n",
    "    axs[i].set_title(f'{titles[i]}')\n",
    "    axs[i].axis('equal')\n",
    "\n",
    "# Add a title on top\n",
    "fig.suptitle('Content routing distribution during non-peak hours', fontsize=16)\n",
    "\n",
    "# Adjust the spacing between subplots and legend\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### PIE-CHART WITH FURTHER BREAKDOWN\n",
    "df = combined_nonpeak_df\n",
    "top10_df = df[df['content'].isin(top_content_list)]\n",
    "popular_df = df[df['content'].str.contains('_top_')]\n",
    "popular_df = popular_df[~popular_df['content'].isin(top_content_list)]\n",
    "nonpopular_df = df[~df['content'].str.contains('_top_|myvideo|_recentlyadded_')]\n",
    "mycontent_df = df[df['content'].str.contains('myvideo')]\n",
    "recentlyadded_df = df[df['content'].str.contains('_recentlyadded_')]\n",
    "\n",
    "# Create list of dfs for pie charts\n",
    "dfs = [top10_df, popular_df, nonpopular_df, mycontent_df, recentlyadded_df]\n",
    "titles = [\"Top-10\", \"Popular\", \"Non-popular\", \"My content\", \"Recently added\"]\n",
    "\n",
    "\n",
    "# Create a figure with 1 row and 5 columns of subplots\n",
    "fig, axs = plt.subplots(1, 5, figsize=(25, 5))\n",
    "\n",
    "# Iterate over the DataFrames and plot the pie charts\n",
    "for i, df in enumerate(dfs):\n",
    "    #df['X-Amz-Cf-Pop'] = df['X-Amz-Cf-Pop'].str[:3]\n",
    "    df['X-Amz-Cf-Pop'] = df['X-Amz-Cf-Pop'].str.replace(\" \", \"N/A\")\n",
    "    city_counts = df['X-Amz-Cf-Pop'].value_counts()\n",
    "    city_percentages = city_counts / len(df) * 100\n",
    "    city_percentages = city_percentages[city_percentages >= 0.1]\n",
    "    axs[i].pie(city_percentages, labels=city_percentages.index, autopct='%1.1f%%', textprops={'fontsize': 8})\n",
    "    axs[i].set_title(f'{titles[i]}')\n",
    "    axs[i].axis('equal')\n",
    "\n",
    "# Add a title on top\n",
    "fig.suptitle('Content routing distribution during non-peak hours (breakdown by PoPs)', fontsize=16)\n",
    "\n",
    "# Adjust the spacing between subplots and legend\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae05954",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HIT/MISS DISTRIBUTION DURING PEAK TIME\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# filter content into dfs\n",
    "df = combined_peak_df\n",
    "top_content_list = []\n",
    "with open(\"top_content_movies.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_movies.csv\"\n",
    "        top_content_list.append(line)\n",
    "with open(\"top_content_tv.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_tv.csv\"\n",
    "        top_content_list.append(line)\n",
    "\n",
    "top10_df = df[df['content'].isin(top_content_list)]\n",
    "popular_df = df[df['content'].str.contains('_top_')]\n",
    "popular_df = popular_df[~popular_df['content'].isin(top_content_list)]\n",
    "nonpopular_df = df[~df['content'].str.contains('_top_|myvideo|_recentlyadded_')]\n",
    "mycontent_df = df[df['content'].str.contains('myvideo')]\n",
    "recentlyadded_df = df[df['content'].str.contains('_recentlyadded_')]\n",
    "\n",
    "\n",
    "dfs = [top10_df, popular_df, nonpopular_df, mycontent_df, recentlyadded_df]\n",
    "titles = [\"Top-10\", \"Popular\", \"Non-popular\", \"My content\", \"Recently added\"]\n",
    "# Create a figure with 1 row and 5 columns of subplots\n",
    "fig, axs = plt.subplots(1, 5, figsize=(25, 5))\n",
    "fig.subplots_adjust(wspace=0.3, hspace=5)\n",
    "\n",
    "# Iterate over the DataFrames and plot the pie charts\n",
    "for i, df in enumerate(dfs):\n",
    "    df['X-Cache'] = df['X-Cache'].str.replace(r'^\\s*$', 'N/A', regex=True) # replace empty strings with N/A\n",
    "    df['X-Cache'] = df['X-Cache'].str.replace('from cloudfront', '')\n",
    "    df.loc[df['Age'] == \" \", 'X-Cache'] = 'Miss' # if Age is empty, we consider it as a miss\n",
    "    df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "    df.loc[df['Age'] > 0, 'X-Cache'] = 'Hit' # if Age > 0, we consider it as HIT\n",
    "    hit_miss_counts = df['X-Cache'].value_counts()\n",
    "    hit_miss_percentages = hit_miss_counts / len(df) * 100\n",
    "    hit_miss_percentages = hit_miss_percentages[hit_miss_percentages >= 0.1]\n",
    "    axs[i].pie(hit_miss_percentages, labels=hit_miss_percentages.index, autopct='%1.1f%%', textprops={'fontsize': 10})\n",
    "    axs[i].set_title(f'{titles[i]}')\n",
    "    axs[i].axis('equal')\n",
    "\n",
    "# Add a title on top\n",
    "fig.suptitle('Hit/Miss distribution during peak time', fontsize=16)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ead40",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HIT/MISS DISTRIBUTION DURING NON-PEAK TIME\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# filter content into dfs\n",
    "df = combined_nonpeak_df\n",
    "top_content_list = []\n",
    "with open(\"top_content_movies.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_movies.csv\"\n",
    "        top_content_list.append(line)\n",
    "with open(\"top_content_tv.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_tv.csv\"\n",
    "        top_content_list.append(line)\n",
    "\n",
    "top10_df = df[df['content'].isin(top_content_list)]\n",
    "popular_df = df[df['content'].str.contains('_top_')]\n",
    "popular_df = popular_df[~popular_df['content'].isin(top_content_list)]\n",
    "nonpopular_df = df[~df['content'].str.contains('_top_|myvideo|_recentlyadded_')]\n",
    "mycontent_df = df[df['content'].str.contains('myvideo')]\n",
    "recentlyadded_df = df[df['content'].str.contains('_recentlyadded_')]\n",
    "\n",
    "\n",
    "dfs = [top10_df, popular_df, nonpopular_df, mycontent_df, recentlyadded_df]\n",
    "titles = [\"Top-10\", \"Popular\", \"Non-popular\", \"My content\", \"Recently added\"]\n",
    "# Create a figure with 1 row and 5 columns of subplots\n",
    "fig, axs = plt.subplots(1, 5, figsize=(25, 5))\n",
    "fig.subplots_adjust(wspace=0.3, hspace=5)\n",
    "\n",
    "# Iterate over the DataFrames and plot the pie charts\n",
    "for i, df in enumerate(dfs):\n",
    "    df['X-Cache'] = df['X-Cache'].str.replace(r'^\\s*$', 'N/A', regex=True) # replace empty strings with N/A\n",
    "    df['X-Cache'] = df['X-Cache'].str.replace('from cloudfront', '')\n",
    "    df.loc[df['Age'] == \" \", 'X-Cache'] = 'Miss' # if Age is empty, we consider it as a miss\n",
    "    df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "    df.loc[df['Age'] > 0, 'X-Cache'] = 'Hit' # if Age > 0, we consider it as HIT\n",
    "    hit_miss_counts = df['X-Cache'].value_counts()\n",
    "    hit_miss_percentages = hit_miss_counts / len(df) * 100\n",
    "    hit_miss_percentages = hit_miss_percentages[hit_miss_percentages >= 0.1]\n",
    "    axs[i].pie(hit_miss_percentages, labels=hit_miss_percentages.index, autopct='%1.1f%%', textprops={'fontsize': 10})\n",
    "    axs[i].set_title(f'{titles[i]}')\n",
    "    axs[i].axis('equal')\n",
    "\n",
    "# Add a title on top\n",
    "fig.suptitle('Hit/Miss distribution during non-peak time', fontsize=16)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e3ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HIT/MISS/FETCH-FROM-X-SERVER DISTRIBUTION OF EDGES\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "combined_peak_df = pd.DataFrame()\n",
    "combined_nonpeak_df = pd.DataFrame()\n",
    "\n",
    "for root, dirs, files in os.walk(RESULT_PATH):\n",
    "    for i, file in enumerate(files):\n",
    "        if file.endswith('.pkl') and \"no-mycontent\" not in root and \"old\" not in file:\n",
    "            print(f\"adding {file}\\tfrom: {root}\")\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                df = pickle.load(f)\n",
    "                if \"nonpeak\" in file_path:\n",
    "                    print(f\"adding {file} in nonpeak\\n\")\n",
    "                    combined_nonpeak_df = pd.concat([combined_nonpeak_df,df], ignore_index=True)\n",
    "                else:\n",
    "                    print(f\"adding {file} in peak\\n\")\n",
    "                    combined_peak_df = pd.concat([combined_peak_df, df], ignore_index=True)\n",
    "\n",
    "peak_count = len(combined_peak_df)\n",
    "nonpeak_count= len(combined_nonpeak_df)\n",
    "print(peak_count, nonpeak_count)\n",
    "\n",
    "\n",
    "# filter content into dfs\n",
    "original_df = pd.concat([combined_peak_df, combined_nonpeak_df])\n",
    "pops = df['X-Amz-Cf-Pop'].unique()\n",
    "\n",
    "num_rows = 4  # Change the number of rows here\n",
    "num_cols = int(np.ceil(len(pops) / num_rows))\n",
    "\n",
    "titles = pops\n",
    "# Create a figure with multiple rows and columns of subplots\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 6))\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "\n",
    "# Flatten the axs array if it has multiple rows\n",
    "if num_rows > 1:\n",
    "    axs = axs.flatten()\n",
    "\n",
    "for i, pop in enumerate(pops):\n",
    "    df = original_df[original_df['X-Amz-Cf-Pop'] == pop]\n",
    "    df['X-Cache'] = df['X-Cache'].str.replace(r'^\\s*$', 'N/A', regex=True)\n",
    "    df['X-Cache'] = df['X-Cache'].str.replace('from cloudfront', '')\n",
    "    df.loc[df['Age'] == \" \", 'X-Cache'] = 'Miss'\n",
    "    df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "    df.loc[df['Age'] > 0, 'X-Cache'] = 'Hit'\n",
    "    df.loc[df['X-Server-IP'] != \" \", 'X-Cache'] = 'X-Fetched'\n",
    "    hit_miss_counts = df['X-Cache'].value_counts()\n",
    "    hit_miss_percentages = hit_miss_counts / len(df) * 100\n",
    "    hit_miss_percentages = hit_miss_percentages[hit_miss_percentages >= 0.1]\n",
    "    axs[i].pie(hit_miss_percentages, labels=hit_miss_percentages.index, autopct='%1.1f%%', textprops={'fontsize': 8})\n",
    "    axs[i].set_title(f'{titles[i]}')\n",
    "    axs[i].axis('equal')\n",
    "\n",
    "# Remove any unused subplots\n",
    "if len(pops) < num_rows * num_cols:\n",
    "    for j in range(len(pops), num_rows * num_cols):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "# Add a title on top\n",
    "fig.suptitle('Hit/Miss distribution', fontsize=16)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd633216",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ORIGIN SHIELD EXPERIMENT\n",
    "RESULT_ORIGSHIELD_PATH = \"./origin-shield-experiment-22-06-2023_22hh_43mm/\"\n",
    "\n",
    "# Load data into dfs\n",
    "for root, dirs, files in os.walk(RESULT_ORIGSHIELD_PATH):\n",
    "        # root: Current directory being scanned\n",
    "        # dirs: Directories inside the current directory\n",
    "        # files: Files inside the current directory\n",
    "        no_origshield_df = pd.DataFrame()\n",
    "        with_origshield_df = pd.DataFrame()\n",
    "        direcyquery_df = pd.DataFrame()\n",
    "        for i, file in enumerate(files):\n",
    "            file_path = os.path.join(root, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            if \"query_to_milan\" in file and \".csv\" in file:\n",
    "                direcyquery_df = df\n",
    "                #print(f\"adding {file} in directquery_df\")\n",
    "            elif \"no_originshield\" in file and \".csv\" in file:\n",
    "                no_origshield_df = df\n",
    "                #print(f\"adding {file} in no_origshield_df\")\n",
    "            elif \"myvideo_originshield\" in file and \".csv\" in file:\n",
    "                 with_origshield_df = df\n",
    "                 #print(f\"adding {file} in with_origshield_df\")\n",
    "\n",
    "\n",
    "direcyquery_df['latency(ms)'] = pd.to_numeric(direcyquery_df['latency(ms)'], errors='coerce')\n",
    "no_origshield_df['latency(ms)'] = pd.to_numeric(no_origshield_df['latency(ms)'], errors='coerce')\n",
    "with_origshield_df['latency(ms)'] = pd.to_numeric(with_origshield_df['latency(ms)'], errors='coerce')\n",
    "\n",
    "\n",
    "# X-axis values\n",
    "x_direcyquery_df = range(1, len(direcyquery_df) + 1)\n",
    "x_no_origshield_df = range(1, len(no_origshield_df) + 1)\n",
    "x_with_origshield_df = range(1, len(with_origshield_df) + 1)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(x_direcyquery_df, direcyquery_df['latency(ms)'], label='direct query to edge')\n",
    "plt.plot(x_no_origshield_df, no_origshield_df['latency(ms)'], label='no origin shield')\n",
    "plt.plot(x_with_origshield_df, with_origshield_df['latency(ms)'], label='with origin shield')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('Response time (ms)')\n",
    "plt.title('Comparison of latency for Origin Shield experiment')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Plotting CDF\n",
    "ecdf_direcyquery_df = sm.distributions.ECDF(direcyquery_df['latency(ms)'])\n",
    "x_direcyquery_df = sorted(direcyquery_df['latency(ms)'].unique())\n",
    "y_direcyquery_df = ecdf_direcyquery_df(x_direcyquery_df)\n",
    "\n",
    "ecdf_no_origshield_df = sm.distributions.ECDF(no_origshield_df['latency(ms)'])\n",
    "x_no_origshield_df = sorted(no_origshield_df['latency(ms)'].unique())\n",
    "y_no_origshield_df = ecdf_no_origshield_df(x_no_origshield_df)\n",
    "\n",
    "ecdf_with_origshield_df = sm.distributions.ECDF(with_origshield_df['latency(ms)'])\n",
    "x_with_origshield_df = sorted(with_origshield_df['latency(ms)'].unique())\n",
    "y_with_origshield_df = ecdf_with_origshield_df(x_with_origshield_df)\n",
    "\n",
    "# Set the figure size\n",
    "#plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot the median lines\n",
    "plt.axhline(0.5, linestyle='--', color='grey')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Response time (ms)')\n",
    "plt.ylabel('CDF')\n",
    "plt.title('CDF of latencies for Origin Shield experiment')\n",
    "\n",
    "plt.plot(x_direcyquery_df, y_direcyquery_df, linestyle='-', label='direct query to Milan')  # Solid line\n",
    "plt.plot(x_no_origshield_df, y_no_origshield_df, linestyle='--', label='no origin shield')  # Dashed line\n",
    "plt.plot(x_with_origshield_df, y_with_origshield_df, linestyle=':', label='with origin shield')  # Dotted line\n",
    "#plt.plot(x_mycontent, y_mycontent, linestyle='-.', label='our content')  # Dash-dot line\n",
    "#plt.plot(x_recentlyadded, y_recentlyadded, linestyle=':', label='recently added content')  # Solid line\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ef9103",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SNAPSHOTS\n",
    "# Load data into dfs\n",
    "RESULT_SNAPSHOT_PATH = \"./snapshots/\"\n",
    "for root, dirs, files in os.walk(RESULT_SNAPSHOT_PATH):\n",
    "        # root: Current directory being scanned\n",
    "        # dirs: Directories inside the current directory\n",
    "        # files: Files inside the current directory\n",
    "        nonpeaktime_df = pd.DataFrame()\n",
    "        nighttime_df = pd.DataFrame()\n",
    "        afterweekend_df = pd.DataFrame()\n",
    "        for i, file in enumerate(files):\n",
    "            file_path = os.path.join(root, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            if \"nonpeaktime\" in file and \".csv\" in file:\n",
    "                nonpeaktime_df = df\n",
    "                print(f\"adding {file} in nonpeaktime_df\")\n",
    "            elif \"night_time\" in file and \".csv\" in file:\n",
    "                nighttime_df = df\n",
    "                print(f\"adding {file} in nighttime_df\")\n",
    "            elif \"nonpeaksunday\" in file and \".csv\" in file:\n",
    "                 afterweekend_df = df\n",
    "                 print(f\"adding {file} in afterweekend_df\")\n",
    "\n",
    "\n",
    "# needed to filter top10 content\n",
    "top_content_list = []\n",
    "with open(\"top_content_movies.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_movies\"\n",
    "        top_content_list.append(line)\n",
    "with open(\"top_content_tv.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip() + \"_url_top_tv\"\n",
    "        top_content_list.append(line)\n",
    "\n",
    "\n",
    "#df = nonpeaktime_df\n",
    "dfs = [nonpeaktime_df, nighttime_df, afterweekend_df]\n",
    "titles = [\"Wednesday Evening\", \"Friday Night\", \"Sunday Morning\"]\n",
    "for i, df in enumerate(dfs):\n",
    "    columns = df.columns[1:]\n",
    "\n",
    "    # Convert the column data to integers\n",
    "    for column in columns:\n",
    "        df[column] = pd.to_numeric(df[column], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Initialize lists to store the results\n",
    "    total_ones = []\n",
    "    ones_top10 = []\n",
    "    ones_unpopular = []\n",
    "\n",
    "    for column in columns:\n",
    "        # Get the total number of 1s\n",
    "        total_ones.append(df[column].sum()/10)\n",
    "        \n",
    "        # Get the number of 1s from content containing \"top\"\n",
    "        ones_top10.append(df[df['content'].str.contains('_top_')][column].sum()/10)\n",
    "        \n",
    "        # Get the number of 1s from content not containing \"top\"\n",
    "        ones_unpopular.append(df[~df['content'].str.contains('_top_')][column].sum()/10)\n",
    "\n",
    "\n",
    "    # Plotting the results\n",
    "    x = range(len(columns))\n",
    "    labels = ['% of All Content', '% of Top Content', '% of Non-Top Content']\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "    width = 0.2\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    ax.bar(x, total_ones, width, color=colors[0], label=labels[0])\n",
    "    ax.bar([i + width for i in x], ones_top10, width, color=colors[1], label=labels[1])\n",
    "    ax.bar([i + 2*width for i in x], ones_unpopular, width, color=colors[2], label=labels[2])\n",
    "\n",
    "    #ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('%')\n",
    "    title = titles[i]\n",
    "    ax.set_title(f'Distribution of content cached on AWS PoPs during {title}')\n",
    "    ax.set_xticks([i + width for i in x])\n",
    "    ax.set_xticklabels(columns, rotation='vertical')\n",
    "    #ax.legend()\n",
    "    ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize='small')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "top10_df = df[df['content'].isin(top_content_list)]\n",
    "popular_df = df[df['content'].str.contains('_top_')]\n",
    "popular_df = popular_df[~popular_df['content'].isin(top_content_list)]\n",
    "nonpopular_df = df[~df['content'].str.contains('_top_|myvideo|_recentlyadded_')]\n",
    "mycontent_df = df[df['content'].str.contains('myvideo')]\n",
    "recentlyadded_df = df[df['content'].str.contains('_recentlyadded_')]\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db1d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
